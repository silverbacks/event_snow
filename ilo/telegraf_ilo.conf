# Telegraf Configuration for HP iLO Hardware Monitoring
# This configuration integrates with the ilo_monitor.py script to collect hardware metrics

# Global configuration
[global_tags]
  # Add any global tags here
  datacenter = "your_datacenter"
  environment = "production"

[agent]
  # Collection interval
  interval = "60s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  hostname = ""
  omit_hostname = false

# INPUT PLUGINS

# iLO Hardware Monitor using exec input plugin - LOCAL MODE
[[inputs.exec]]
  # Command to execute for local hardware monitoring
  commands = [
    "python3 /path/to/ilo_monitor.py --local"
  ]
  
  # Timeout for command execution
  timeout = "60s"
  
  # Data format to consume (InfluxDB line protocol)
  data_format = "influx"
  
  # Tags to add to all metrics
  [inputs.exec.tags]
    source = "ilo_monitor_local"
    monitor_type = "hardware"
    collection_mode = "local_console"

# Alternative configuration for mixed local and remote monitoring
# [[inputs.exec]]
#   commands = [
#     "python3 /path/to/ilo_monitor.py --config /path/to/ilo_config.json"
#   ]
#   timeout = "60s"
#   data_format = "influx"
#   [inputs.exec.tags]
#     source = "ilo_monitor_mixed"
#     monitor_type = "hardware"

# Single remote iLO monitoring (if needed)
# [[inputs.exec]]
#   commands = [
#     "python3 /path/to/ilo_monitor.py --host ilo.example.com --username admin --password secret --version 5"
#   ]
#   timeout = "60s"
#   data_format = "influx"
#   [inputs.exec.tags]
#     source = "ilo_monitor_remote"
#     ilo_host = "ilo.example.com"

# HTTP input plugin for webhook-style monitoring (optional)
# [[inputs.http]]
#   urls = ["http://localhost:8080/ilo-metrics"]
#   timeout = "30s"
#   method = "GET"
#   data_format = "json"
#   json_name_key = "measurement"
#   json_time_key = "timestamp"
#   json_time_format = "unix"

# PROCESSOR PLUGINS

# Add hostname processor to ensure proper tagging for Prometheus
[[processors.override]]
  # Override hostname if needed for Prometheus labels
  [processors.override.tags]
    # host = "physical-server-01"
    # environment = "production"

# Rename measurements for better Prometheus metric names
[[processors.rename]]
  [[processors.rename.replace]]
    measurement = "ilo_system_health"
    dest = "ilo_health"
  [[processors.rename.replace]]
    measurement = "ilo_temperature_*"
    dest = "ilo_temp"
  [[processors.rename.replace]]
    measurement = "ilo_fan_*"
    dest = "ilo_fan"
  [[processors.rename.replace]]
    measurement = "ilo_power_*"
    dest = "ilo_power"
  [[processors.rename.replace]]
    measurement = "ilo_memory_*"
    dest = "ilo_memory"

# Convert string fields to numeric for Prometheus compatibility
[[processors.converter]]
  [processors.converter.fields]
    integer = ["*_numeric", "*_rpm", "*_percent", "*_mb", "*_gb", "*_watts", "*_mhz"]
    float = ["temperature_*", "*_celsius", "*_fahrenheit", "load_*", "usage_percent"]
    string = ["status", "health", "state", "manufacturer", "type", "source"]

# Add Prometheus-friendly labels and handle status mapping
[[processors.starlark]]
  source = '''
def apply(metric):
    # Convert status strings to numeric values for Prometheus
    status_map = {
        "OK": 1, "Good": 1, "Enabled": 1, "On": 1, "Normal": 1,
        "Warning": 2, "Degraded": 2, "Caution": 2,
        "Critical": 3, "Error": 3, "Failed": 3, "Off": 3, "Fault": 3,
        "Unknown": 0, "Absent": 0, "Not Present": 0
    }
    
    # Process status fields
    for field_name in list(metric.fields.keys()):
        if field_name in ["status", "health", "state"]:
            status_value = metric.fields[field_name]
            if isinstance(status_value, str):
                numeric_value = status_map.get(status_value, 0)
                metric.fields[field_name + "_code"] = numeric_value
                # Keep original as tag for Prometheus label
                metric.tags[field_name] = status_value
                del metric.fields[field_name]
    
    # Add derived metrics for monitoring
    measurement = metric.name
    if "temperature" in measurement:
        # Add temperature health indicator
        temp_value = metric.fields.get("value", 0)
        if temp_value > 85:
            metric.fields["temp_health"] = 3  # Critical
        elif temp_value > 75:
            metric.fields["temp_health"] = 2  # Warning
        elif temp_value > 0:
            metric.fields["temp_health"] = 1  # OK
        else:
            metric.fields["temp_health"] = 0  # Unknown
    
    elif "fan" in measurement:
        # Add fan health indicator
        rpm = metric.fields.get("speed_rpm", 0)
        percent = metric.fields.get("speed_percent", 0)
        if rpm == 0 and percent == 0:
            metric.fields["fan_health"] = 3  # Critical - not spinning
        elif rpm < 500 or percent < 10:
            metric.fields["fan_health"] = 2  # Warning - low speed
        else:
            metric.fields["fan_health"] = 1  # OK
    
    return metric
'''

# AGGREGATOR PLUGINS

# Calculate statistics over time windows
[[aggregators.basicstats]]
  period = "5m"
  drop_original = false
  stats = ["count", "diff", "rate", "sum", "mean", "stdev", "s2", "min", "max"]
  
  # Only aggregate numeric fields
  fieldpass = ["*_watts", "*_rpm", "*_percent", "temperature_*", "*_numeric"]

# Calculate histogram for temperature values
[[aggregators.histogram]]
  period = "5m"
  drop_original = false
  buckets = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]
  
  # Only histogram temperature fields
  fieldpass = ["temperature_*"]

# OUTPUT PLUGINS

# Prometheus output - PRIMARY OUTPUT for metrics
[[outputs.prometheus_client]]
  # Listen address and port for Prometheus to scrape
  listen = ":9273"
  
  # Metrics path for Prometheus scraping
  path = "/metrics"
  
  # Prometheus metric version (2 is recommended)
  metric_version = 2
  
  # Export timestamp (recommended for hardware metrics)
  export_timestamp = true
  
  # Collectors to exclude (reduce noise)
  collectors_exclude = ["gocollector", "process"]
  
  # Treat string values as labels (important for InfluxDB format compatibility)
  string_as_label = true
  
  # Prometheus metric name mapping
  [outputs.prometheus_client.tagpass]
    # Only include hardware monitoring metrics
    source = ["ilo_monitor*"]
  
  # Additional Prometheus-specific settings
  # [outputs.prometheus_client.tagdrop]
  #   # Drop internal metrics if needed
  #   internal = ["true"]

# InfluxDB v2 output (SECONDARY - for backup/detailed storage)
# [[outputs.influxdb_v2]]
#   urls = ["http://localhost:8086"]
#   token = "$INFLUX_TOKEN"
#   organization = "your_org"
#   bucket = "ilo_metrics"
#   timeout = "10s"

# File output for debugging and InfluxDB line protocol validation
[[outputs.file]]
  files = ["/var/log/telegraf/ilo_metrics_influx_format.log"]
  rotation_interval = "24h"
  rotation_max_size = "100MB"
  rotation_max_archives = 3
  
  # Use InfluxDB line protocol format
  data_format = "influx"
  
  # Add timestamp precision
  influx_max_line_bytes = 0
  influx_sort_fields = false
  influx_uint_support = false

# Console output for debugging (disable in production)
# [[outputs.file]]
#   files = ["stdout"]
#   data_format = "influx"

# ALERT OUTPUTS for Prometheus AlertManager integration

# Webhook output for Prometheus AlertManager
# [[outputs.http]]
#   url = "http://localhost:9093/api/v1/alerts"
#   timeout = "5s"
#   method = "POST"
#   data_format = "json"
#   
#   # Only send critical hardware alerts
#   [outputs.http.tagpass]
#     status = ["Critical", "Error", "Failed"]
#   
#   # Custom headers for AlertManager
#   [outputs.http.headers]
#     Content-Type = "application/json"
#     User-Agent = "telegraf-ilo-monitor"

# Send metrics to Elasticsearch for log analysis (optional)
# [[outputs.elasticsearch]]
#   urls = ["http://localhost:9200"]
#   timeout = "5s"
#   enable_sniffer = false
#   health_check_interval = "10s"
#   index_name = "ilo-metrics-%Y.%m.%d"
#   manage_template = true
#   
#   # Template for InfluxDB line protocol compatibility
#   template_name = "ilo_metrics"
#   overwrite_template = false

# MONITORING AND HEALTH CHECKS

# Monitor Telegraf itself
[[inputs.internal]]
  collect_memstats = true

# System metrics for the Telegraf host
[[inputs.system]]
  fielddrop = ["uptime_format"]

[[inputs.cpu]]
  percpu = true
  totalcpu = true
  collect_cpu_time = false
  report_active = false

[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

[[inputs.diskio]]

[[inputs.kernel]]

[[inputs.mem]]

[[inputs.processes]]

[[inputs.swap]]

[[inputs.net]]

# Custom health check for iLO connectivity
[[inputs.http_response]]
  # Test iLO web interface connectivity
  urls = [
    "https://ilo1.example.com",
    "https://ilo2.example.com"
  ]
  method = "GET"
  timeout = "10s"
  insecure_skip_verify = true
  
  [inputs.http_response.tags]
    check_type = "ilo_connectivity"